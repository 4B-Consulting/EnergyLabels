{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T00:13:16.419445Z",
     "start_time": "2025-07-19T00:13:16.409168Z"
    }
   },
   "cell_type": "code",
   "source": "import pandas as pd",
   "id": "ae97526d2fa49437",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T00:13:16.468768Z",
     "start_time": "2025-07-19T00:13:16.447821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"../data/gt.csv\")\n",
    "df.rename(columns={\n",
    "    'Pieces1': 'Pieces',\n",
    "    'Manufacturer1': \"Manufacturer\",\n",
    "    \"SubType1\": \"SubType\",\n",
    "    \"HxType1\": \"HxType\",\n",
    "    \"NominelEffectEach1\": \"NominalEffectEach\",\n",
    "    \"Year1\": \"Year\"\n",
    "}, inplace=True)\n",
    "df.head()"
   ],
   "id": "95b8f15208dd46af",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                              S_text  \\\n",
       "0  Fjernvarme med isoleret veksler (indirekte anl...   \n",
       "1                            Eksisterende fjernvarme   \n",
       "2  Fjernvarme med uisoleret veksler (indirekte an...   \n",
       "3  Fjernvarme med isoleret veksler (indirekte anl...   \n",
       "4  Fjernvarme med isoleret veksler (indirekte anl...   \n",
       "\n",
       "                                              L_text  Pieces   Manufacturer  \\\n",
       "0  Bygningen opvarmes med fjernvarme. Anlægget er...     1.0        Unknown   \n",
       "1                                                NaN     1.0        Unknown   \n",
       "2  Bygningen opvarmes med fjernvarme. Anlægget er...     1.0        Unknown   \n",
       "3  Ejendommen opvarmes med fjernvarme fra HOFOR.\\...     1.0  Danfoss Redan   \n",
       "4  Bygningen opvarmes med fjernvarme. Anlægget er...     1.0        Unknown   \n",
       "\n",
       "  SubType                  HxType NominalEffectEach         Year  \n",
       "0     NaN   Isoleret varmeveksler               NaN          NaN  \n",
       "1     NaN                     NaN               NaN          NaN  \n",
       "2     NaN  Uisoleret varmeveksler               NaN   After 1980  \n",
       "3     NaN   Isoleret varmeveksler               NaN          NaN  \n",
       "4     NaN   Isoleret varmeveksler               NaN  Before 1970  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S_text</th>\n",
       "      <th>L_text</th>\n",
       "      <th>Pieces</th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>SubType</th>\n",
       "      <th>HxType</th>\n",
       "      <th>NominalEffectEach</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fjernvarme med isoleret veksler (indirekte anl...</td>\n",
       "      <td>Bygningen opvarmes med fjernvarme. Anlægget er...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Isoleret varmeveksler</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eksisterende fjernvarme</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fjernvarme med uisoleret veksler (indirekte an...</td>\n",
       "      <td>Bygningen opvarmes med fjernvarme. Anlægget er...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Uisoleret varmeveksler</td>\n",
       "      <td>NaN</td>\n",
       "      <td>After 1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fjernvarme med isoleret veksler (indirekte anl...</td>\n",
       "      <td>Ejendommen opvarmes med fjernvarme fra HOFOR.\\...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Danfoss Redan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Isoleret varmeveksler</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fjernvarme med isoleret veksler (indirekte anl...</td>\n",
       "      <td>Bygningen opvarmes med fjernvarme. Anlægget er...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Isoleret varmeveksler</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Before 1970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create a number for each label in the dataset. This approach is not extensible: if the manufacturer is not present in the training data, the model won't be able to predict it.",
   "id": "48721a0cc4c02c04"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T00:13:16.518569Z",
     "start_time": "2025-07-19T00:13:16.508281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_cols = df.columns[2:]\n",
    "\n",
    "label_maps = {}\n",
    "for col in target_cols:\n",
    "    if df[col].dtype == \"object\":\n",
    "        df.fillna({col: \"NaN\"})\n",
    "        label_maps[col] = {label: idx for idx, label in enumerate(df[col].unique())}\n",
    "        df[f\"{col}_idx\"] = df[col].map(label_maps[col])"
   ],
   "id": "9e83dc2fdc466f06",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# NER",
   "id": "f90b4bfe88937aa7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T00:20:06.522138Z",
     "start_time": "2025-07-19T00:20:05.269153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "from tqdm.auto import trange\n",
    "import sys\n",
    "sys.path.append(\"../scripts\")\n",
    "from NERmodel import TokenClassifier\n",
    "from NER_ground_truth import ner_data"
   ],
   "id": "db9648455b608fa7",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T00:23:19.789330Z",
     "start_time": "2025-07-19T00:20:56.471918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ner_gt = ner_data('../data/data_district_heating.xlsx')\n",
    "ner_gt.head()"
   ],
   "id": "b11398e418369ae7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2272/2272 [02:20<00:00, 16.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                text  \\\n",
       "0  Fjernvarme med isoleret veksler (indirekte anl...   \n",
       "1                           Eksisterende fjernvarme    \n",
       "2  Fjernvarme med uisoleret veksler (indirekte an...   \n",
       "3  Fjernvarme med isoleret veksler (indirekte anl...   \n",
       "4  Fjernvarme med isoleret veksler (indirekte anl...   \n",
       "\n",
       "                                               words  \\\n",
       "0  [fjernvarme, med, isoleret, veksler, (, indire...   \n",
       "1                         [eksisterende, fjernvarme]   \n",
       "2  [fjernvarme, med, uisoleret, veksler, (, indir...   \n",
       "3  [fjernvarme, med, isoleret, veksler, (, indire...   \n",
       "4  [fjernvarme, med, isoleret, veksler, (, indire...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [[tensor(1.0188), tensor(1.2181), tensor(0.024...   \n",
       "1  [[tensor(1.0928), tensor(0.8145), tensor(0.337...   \n",
       "2  [[tensor(1.0735), tensor(1.2092), tensor(0.108...   \n",
       "3  [[tensor(0.8679), tensor(1.1397), tensor(-0.12...   \n",
       "4  [[tensor(1.0224), tensor(1.1423), tensor(0.114...   \n",
       "\n",
       "                                              labels  \n",
       "0  [[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0....  \n",
       "1  [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0....  \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0....  \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0....  \n",
       "4  [[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0....  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fjernvarme med isoleret veksler (indirekte anl...</td>\n",
       "      <td>[fjernvarme, med, isoleret, veksler, (, indire...</td>\n",
       "      <td>[[tensor(1.0188), tensor(1.2181), tensor(0.024...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eksisterende fjernvarme</td>\n",
       "      <td>[eksisterende, fjernvarme]</td>\n",
       "      <td>[[tensor(1.0928), tensor(0.8145), tensor(0.337...</td>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fjernvarme med uisoleret veksler (indirekte an...</td>\n",
       "      <td>[fjernvarme, med, uisoleret, veksler, (, indir...</td>\n",
       "      <td>[[tensor(1.0735), tensor(1.2092), tensor(0.108...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fjernvarme med isoleret veksler (indirekte anl...</td>\n",
       "      <td>[fjernvarme, med, isoleret, veksler, (, indire...</td>\n",
       "      <td>[[tensor(0.8679), tensor(1.1397), tensor(-0.12...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fjernvarme med isoleret veksler (indirekte anl...</td>\n",
       "      <td>[fjernvarme, med, isoleret, veksler, (, indire...</td>\n",
       "      <td>[[tensor(1.0224), tensor(1.1423), tensor(0.114...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T00:29:26.851628Z",
     "start_time": "2025-07-19T00:29:26.844149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TokenDataset(Dataset):\n",
    "    def __init__(self, tokens_list, labels_list):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tokens_list: List of token embeddings (each item is a tensor of shape [seq_len, embedding_dim])\n",
    "            labels_list: List of labels (each item is a tensor of shape [seq_len, 7])\n",
    "        \"\"\"\n",
    "        self.tokens_list = tokens_list\n",
    "        self.labels_list = labels_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokens_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens = torch.stack(self.tokens_list[idx])\n",
    "        labels = torch.from_numpy(self.labels_list[idx])\n",
    "        return tokens, labels"
   ],
   "id": "7a5938bc4d095b47",
   "outputs": [],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T00:29:31.497868Z",
     "start_time": "2025-07-19T00:29:31.493310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function to handle variable-length sequences using torch's pad_sequence\n",
    "    \"\"\"\n",
    "    tokens_list, labels_list = zip(*batch)\n",
    "\n",
    "    # Pad tokens and labels using torch's built-in function\n",
    "    padded_tokens = pad_sequence(tokens_list, batch_first=True, padding_value=0.0)\n",
    "    padded_labels = pad_sequence(labels_list, batch_first=True, padding_value=0.0)\n",
    "\n",
    "    # Create attention masks\n",
    "    attention_masks = torch.zeros(len(tokens_list), padded_tokens.shape[1])\n",
    "    for i, tokens in enumerate(tokens_list):\n",
    "        attention_masks[i, :len(tokens)] = 1\n",
    "\n",
    "    return padded_tokens, padded_labels, attention_masks"
   ],
   "id": "d65699285cfa75b",
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T00:33:48.655030Z",
     "start_time": "2025-07-19T00:33:48.637501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fit(df, embedding_dim=768, hidden_dim=49, num_classes=7,\n",
    "        initial_batch_size=8, max_batch_size=64, num_epochs=1000,\n",
    "        eval_split=0.2):\n",
    "    \"\"\"\n",
    "    Train the token classifier\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with 'tokens' and 'labels' columns\n",
    "            - tokens: List of token embeddings (arrays of shape [seq_len, embedding_dim])\n",
    "            - labels: List of label arrays (arrays of shape [seq_len, 7])\n",
    "        embedding_dim: Token embedding dimension\n",
    "        hidden_dim: Hidden layer dimension\n",
    "        num_classes: Number of output classes\n",
    "        initial_batch_size: Starting batch size\n",
    "        max_batch_size: Maximum batch size\n",
    "        num_epochs: Number of training epochs\n",
    "        eval_split: Fraction of data for evaluation\n",
    "\n",
    "    Returns:\n",
    "        dict: Training and evaluation losses every 50 epochs\n",
    "    \"\"\"\n",
    "\n",
    "    # Split data\n",
    "    train_tokens, eval_tokens, train_labels, eval_labels = train_test_split(\n",
    "        df['tokens'].tolist(), df['labels'].tolist(),\n",
    "        test_size=eval_split, random_state=42\n",
    "    )\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = TokenDataset(train_tokens, train_labels)\n",
    "    eval_dataset = TokenDataset(eval_tokens, eval_labels)\n",
    "\n",
    "    # Initialize model\n",
    "    model = TokenClassifier(embedding_dim, hidden_dim, num_classes)\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction='none')  # For multi-label classification\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Training tracking\n",
    "    train_losses = []\n",
    "    eval_losses = []\n",
    "    current_batch_size = initial_batch_size\n",
    "\n",
    "    print(f\"Starting training with batch size {current_batch_size}\")\n",
    "\n",
    "    pbar = trange(num_epochs)\n",
    "    for epoch in pbar:\n",
    "        # Create data loaders with current batch size\n",
    "        train_loader = DataLoader(train_dataset, batch_size=current_batch_size,\n",
    "                                 shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        num_batches = 0\n",
    "\n",
    "        for tokens, labels, attention_mask in train_loader:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            logits = model(tokens)\n",
    "\n",
    "            # Calculate loss only for non-padded tokens\n",
    "            loss_per_token = criterion(logits, labels)\n",
    "            loss_per_token = loss_per_token * attention_mask.unsqueeze(-1)\n",
    "            loss = loss_per_token.sum() / attention_mask.sum()\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / num_batches\n",
    "\n",
    "        # Evaluate every 50 epochs using the entire evaluation dataset\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            model.eval()\n",
    "\n",
    "            # Create evaluation loader with batch size 1 to process entire dataset\n",
    "            eval_loader = DataLoader(eval_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "            total_eval_loss = 0.0\n",
    "            total_tokens = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for tokens, labels, attention_mask in eval_loader:\n",
    "                    logits = model(tokens)\n",
    "\n",
    "                    loss_per_token = criterion(logits, labels)\n",
    "                    loss_per_token = loss_per_token * attention_mask.unsqueeze(-1)\n",
    "\n",
    "                    # Accumulate total loss and total tokens\n",
    "                    total_eval_loss += loss_per_token.sum().item()\n",
    "                    total_tokens += attention_mask.sum().item()\n",
    "\n",
    "            # Calculate average loss across all tokens in evaluation set\n",
    "            avg_eval_loss = total_eval_loss / total_tokens\n",
    "\n",
    "            train_losses.append(avg_epoch_loss)\n",
    "            eval_losses.append(avg_eval_loss)\n",
    "\n",
    "            pbar.set_postfix({\n",
    "                \"Train Loss\": f\"{avg_epoch_loss:.4f}\",\n",
    "                \"Eval Loss\": f\"{avg_eval_loss:.4f}\",\n",
    "                \"Batch Size\": f\"{current_batch_size}\",\n",
    "            })\n",
    "\n",
    "        # Increase batch size when loss reaches 0 (or very close to 0)\n",
    "        if avg_epoch_loss < 0.01 and current_batch_size < max_batch_size:\n",
    "            current_batch_size = min(current_batch_size * 2, max_batch_size)\n",
    "            print(f\"Increasing batch size to {current_batch_size}\")\n",
    "\n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'eval_losses': eval_losses,\n",
    "        'model': model\n",
    "    }"
   ],
   "id": "ea6e73ff17a6f778",
   "outputs": [],
   "execution_count": 102
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-07-19T00:33:49.206711Z"
    }
   },
   "cell_type": "code",
   "source": "losses_and_model = fit(ner_gt)",
   "id": "e7817907f7dc2b3c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with batch size 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e7c7a1524f7343c8aa644159060b0464"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing batch size to 16\n",
      "Increasing batch size to 32\n",
      "Increasing batch size to 64\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d2e6d2ce3a054172"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

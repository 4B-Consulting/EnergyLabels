---
title: Implementing the NER
author: "Carlo Rosso"
date: 2025-07-16
---

-[x] Tokenizer into words.
-[x] Neural network, for word class prediction.
-[x] Chatbot for evaluation.
-[x] Recompose the words into a tagged sentence.
-[x] Decompose chatbot result into tags per word.
-[ ] Store sentences embeddings, to avoid recomputation.
-[ ] Store good tagged sentences (closest to neural network result).

1. extract random samples' batch
2. for each sample, tokenize the description by word
3. neural network on each token to identify its class: (Pieces, Manufacturer,
   SubType, ...)
4. check whether the tagging of each sample is correct with a chatbot.
5. save good result in a DataFrame, for future extractions.
6. repeat in batch with random extraction.

I can improve the above model:
- recurrent neural network to mix the tokens corresponding to the same word
- llm to check on the correctness of each word: it return the correct
  prediction, if it is unchanged than the loss is 0, otherwise the loss for each
  word is computed. This allow for better loss.
- NER to take into consideration the context of the word, and so it predicts the
  class of a word, but it has a sentence as an input.
